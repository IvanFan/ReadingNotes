# Quick Guide about how to setup kubernetes with kops and third-party firewall FortinetGate

## Overview
AWS has some concepts about the definition of their cloud solution. It's better to have a basic understanding about those concept before coming to the setup process.

The entire document can be divided into 3 parts:

- Basic concepts about AWS Virtual Private Cloud(VPC)
- How to setup the k8s cluster on AWS with kops
- How to setup the firewall solution with FortinetGate

As a software enginer, I'm new to the area of network security. But it's exciting to build sth relevant to security from scratch. Besides, as a developer, I always want to understand all details of the new knowledge. So if you just want to setup the cluster with firewall, please directly jump to the second part of this document. If I have any misunderstanding about those technologies, please let me know. Thanks

## Basic concepts about AWS Virtual Private Cloud(VPC)

### VPC


> A virtual private cloud (VPC) is a virtual network dedicated to your AWS account. It is logically isolated from other virtual networks in the AWS Cloud. You can launch your AWS resources, such as Amazon EC2 instances, into your VPC.

Above is the definition from AWS. In summary, VPC is a virtual network/scope pre-defined by AWS.

### Region and Availability Zone


> Each region is completely independent. Each Availability Zone is isolated, but the Availability Zones in a region are connected through low-latency links. The following diagram illustrates the relationship between regions and Availability Zones.


![Availability Zones](https://github.com/IvanFan/ReadingNotes/blob/master/dailyNotes/2017/07/27/aws_regions.png)

There are many reasons of using availability zones. For example, High Availability and DMZ

### Subnet


> A subnet is a logical division of the IP address range into smaller logical networks. 
Each subnet inside a VPC is connected to a router which routes the traffic between the different subnets in the VPC – this is how you get connectivity between different subnets inside the VPC


OK, now it's time to do a quick review about those concepts before we go deep into more details. 
So, here is the relationship about VPC, Availability Zone and Subnet: 

![region and zone](https://github.com/IvanFan/ReadingNotes/blob/master/dailyNotes/2017/07/27/vpc-diagram.png)

![subnet](https://github.com/IvanFan/ReadingNotes/blob/master/dailyNotes/2017/07/27/subnets-diagram.png)

As you can see, one aws account can have multiple VPCs. For each VPC, there maybe multiple Availability Zonez and within each zone, there maybe multiple subnets. And for each subnet, there will have multiple instances.

One extra question: How does AWS define the Subnet within the VPC?

Answer: CIDR

> Classless Inter-Domain Routing (CIDR, /ˈsaɪdər/ or /ˈsɪdər/) is a method for allocating IP addresses and IP routing. 
 Its goal was to slow the growth of routing tables on routers across the Internet, and to help slow the rapid exhaustion of IPv4 addresses
IP addresses are described as consisting of two groups of bits in the address: the most significant bits are the network prefix, which identifies a whole network or subnet, and the least significantset forms the host identifier, which specifies a particular interface of a host on that network. This division is used as the basis of traffic routing between IP networks and for address allocation policies. Classful network design for IPv4 sized the network prefix as one or more 8-bit groups, resulting in the blocks of Class A, B, or C addresses. Classless Inter-Domain Routing allocates address space to Internet service providers and end users on any address bit boundary, instead of on 8-bit segments. In IPv6, however, the interface identifier has a fixed size of 64 bits by convention, and smaller subnets are never allocated to end users.


Now we want to know more about subnet.

### Public Subnet

> If a subnet's traffic is routed to an Internet gateway, the subnet is known as a public subnet.

### Private Subnet

> If a subnet doesn't have a route to the Internet gateway, the subnet is known as a private subnet.

### Internet gateway

> An Internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows communication between instances in your VPC and the Internet. It therefore imposes no availability risks or bandwidth constraints on your network traffic.

> An Internet gateway serves two purposes: to provide a target in your VPC route tables for Internet-routable traffic, and to perform network address translation (NAT) for instances that have been assigned public IPv4 addresses.



### Subnet Routing

> Each subnet must be associated with a route table, which specifies the allowed routes for outbound traffic leaving the subnet. Every subnet that you create is automatically associated with the main route table for the VPC.

### route table 

> A route table contains a set of rules, called routes, that are used to determine where network traffic is directed.

> Each subnet in your VPC must be associated with a route table; the table controls the routing for the subnet. A subnet can only be associated with one route table at a time, but you can associate multiple subnets with the same route table.


Then how can we enable the access to the private subnet?

### NAT 

> You can use a NAT device to enable instances in a private subnet to connect to the Internet (for example, for software updates) or other AWS services, but prevent the Internet from initiating connections with the instances. A NAT device forwards traffic from the instances in the private subnet to the Internet or other AWS services, and then sends the response back to the instances. When traffic goes to the Internet, the source IPv4 address is replaced with the NAT device’s address and similarly, when the response traffic goes to those instances, the NAT device translates the address back to those instances’ private IPv4 addresses.

### NAT gateway

> You can use a network address translation (NAT) gateway to enable instances in a private subnet to connect to the Internet or other AWS services, but prevent the Internet from initiating a connection with those instances. 

In summary, it's like this:

![public/private subnets](https://github.com/IvanFan/ReadingNotes/blob/master/dailyNotes/2017/07/27/aws_terraform_network_diagram.png)


Besides, there is a good blog about this [Terraform: AWS VPC with Private and Public Subnets](https://nickcharlton.net/posts/terraform-aws-vpc.html)

So far so good, now we have a basic understanding about the architecture of the entire network structure. However, we still have some other concepts need to learn.

### Network interface

> An elastic network interface (referred to as a network interface in this documentation) is a virtual network interface that you can attach to an instance in a VPC. Network interfaces are available only for instances running in a VPC.

> You can create a network interface, attach it to an instance, detach it from an instance, and attach it to another instance. The attributes of a network interface follow it as it's attached or detached from an instance and reattached to another instance. When you move a network interface from one instance to another, network traffic is redirected to the new instance.

### Elastic Load Balance

> Elastic Load Balancing distributes incoming application traffic across multiple EC2 instances, in multiple Availability Zones. This increases the fault tolerance of your applications.

> The load balancer serves as a single point of contact for clients, which increases the availability of your application. You can add and remove instances from your load balancer as your needs change, without disrupting the overall flow of requests to your application. Elastic Load Balancing scales your load balancer as traffic to your application changes over time, and can scale to the vast majority of workloads automatically.


Now we have a question: What's the difference between load balance and internet gateway? How they work together?

Answer: I found this from the internet.
> When you receive incoming traffic through the load balancer, the responses will go out the same way. However, traffic that is originating from your instance will not pass through the load balancer. Instead, it is sent directly from the public IP address of your instance out to the Internet. The ELB is not involved in that scenario.

> With VPC, you have two options. The first one involves assigning an Elastic IP to each instance, like you mentioned. In order for this to work, you will also need to have a default route (0.0.0.0/0) pointing to the Internet Gateway. This will essentially make the subnet public. If you prefer keeping the instances in a private subnet and more isolated from the Internet, you can route the outgoing Internet traffic (minus ELB traffic) through a NAT instance. In this scenario, the internal instances will not need public IP addresses. All traffic will instead appear to be originating from the NAT instance, which runs in a public subnet and will have an Elastic IP.

> (As a side note, EC2-VPC with Default VPC offers dynamic public IP addresses. In some cases, that could be a replacement for Elastic IPs.)

### Inbound and outbound
Inbound request is the request inited from the outside network and come into the instance
Outbound request is inited within the instance
The response of outside request is still an inbound request

Inbound traffic means traffic coming into the instance. The origin of the traffic can be an instance on the same subnet, on a different subnet on the same VPC, or a server on the other side of the world.

### Security Group

> A security group acts as a virtual firewall that controls the traffic for one or more instances. When you launch an instance, you associate one or more security groups with the instance. You add rules to each security group that allow traffic to or from its associated instances.

### AWS ACL

> In an ACL (and, as we shell see, with AWS ACL also) each rule is numbered. When a packet arrives at the firewall, it gets evaluated against the rules of the ACL starting with the rule with the lowest number. When a match is found, the rule is enforced and the packet is permitted or dropped. The rules with higher numbering than the matched rule are not evaluated. If the packet doesn’t matches a rule, the next rule with a higher number is evaluated and so forth.

* This brings us to an important difference between ACL and SG, the scope of there influence. As we saw, a SG is associated to an EC2 instance and defines the allowed inbound and outbound traffic for that instance. An ACL on the other hand is associated with a subnet. 


## How to setup the k8s cluster on AWS with kops

Kops is a tool to help you get a production grade Kubernetes cluster up and running.

It's officially supported by the k8s team at the moment and updated quickly for new features.

Kops has a good document about setup the cluster.
To simplify the setup process, I packaged some commands together into shell scripts after working hours.

Here are some simple examples

```
init_aws_cluster_config.sh

#!/usr/bin/env bash
export NAME=yourclustername
export KOPS_STATE_STORE=s3 storage link
echo $NAME
```


```
show_aws_auth.sh

#!/usr/bin/env bash
cat .aws/credentials
```

```
create_aws_pro_cluster.sh

#!/usr/bin/env bash
kops create cluster  --name=${NAME} \
    --zones=ap-southeast-2a,ap-southeast-2b,ap-southeast-2c \
    --master-zones=ap-southeast-2a,ap-southeast-2b,ap-southeast-2c \
    --node-count=3 \
    --node-size=m3.medium \
    --master-size=m3.medium \
    --topology private \
    --networking canal \
    --yes
```

```
add_ui_dashboard_to_cluster.sh

#!/usr/bin/env bash
echo "Begin to install UI dashboard for the cluster"
kubectl create -f https://raw.githubusercontent.com/kubernetes/kops/master/addons/kubernetes-dashboard/v1.6.1.yaml
echo "---------------------------------"
echo "Dashboard URL:"
echo "https://api.${NAME}/ui"
echo "---------------------------------"
echo "login credentials:"
echo "Username: admin"
echo echo "PW:"
kops get secrets kube --type secret -oplaintext
```

```
setup_cluster_monitoring.sh

#!/usr/bin/env bash
kubectl create -f heapster/deploy/kube-config/influxdb
echo "Grafana default username & pw: admin"
echo "InfluxDB default Database name: k8s     un&pw: root"
```
Here we need to download the heapster deploy folder from github

```
check_sys_status.sh

#!/usr/bin/env bash
echo "################## Get K8s Nodes ##############"
kubectl get nodes
echo "################## Validate K8s cluster ##############"
kops validate cluster
echo "################## Syste description ##############"
kubectl -n kube-system get po
```

If all good, now we should have a cluster setup in AWS. The cluster will have 3 master instances and 3 nodes in different availability zones for HA. Meanwhile, we also added an UI dashboard for serivces and deployment management and a monitoring system for the server status.



##  How to setup the firewall solution with FortinetGate

If we login to the AWS console management dashboard, it's easy to see that we have 6 subnets: 3 private subnets for master instances and 3 public subnets for nodes with "utility-" as prefix.

The main point for setting up firewall is to let all traffic first come to the firewall and then come back to the subnet they want to conencted to.

The result is: all current public subnets will become private subnets.

![target](https://github.com/IvanFan/ReadingNotes/blob/master/dailyNotes/2017/07/27/firewall%20solution.png)



### Create the Public subnet for each zone

Before launching the Fortinet Gate VM, we need to create 3 Public subnet for those VMs.

We can come to the VPC dashboard, click Subnet from the side menu and click the 'Create Subnet'

The difficult point here is to use CIDR to assign IPs to the subnet.


