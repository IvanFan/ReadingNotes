# Java Thread


## Cost of multi threads

- complex
- context switch is expensive
- occupy resources e.g. CPU

## Concurrency


## How to create thread in java

- extends Thread class and overwrite run()
- implements Runnable interface 


Java 内存模型和硬件内存架构之间的桥接
上面已经提到，Java 内存模型与硬件内存架构之间存在差异。硬件内存架构没有区分线程栈和堆。对于硬件，所 有的线程栈和堆都分布在主内中。部分线程栈和堆可能有时候会出现在 CPU 缓存中和 CPU 内部的寄存器 中。如下图所示:
当对象和变量被存放在计算机中各种不同的内存区域中时，就可能会出现一些具体的问题。主要包括如下两个方
面:
• 线程对共享变量修改的可见性
• 当读，写和检查共享变量时出现 race conditions
下面我们专门来解释以下这两个问题。 共享对象可见性
如果两个或者更多的线程在没有正确的使用 volatile 声明或者同步的情况下共享一个对象，一个线程更新这个共 享对象可能对其它线程来说是不接见的。
想象一下，共享对象被初始化在主存中。跑在 CPU 上的一个线程将这个共享对象读到 CPU 缓存中。然后修改 了这个对象。只要 CPU 缓存没有被刷新会主存，对象修改后的版本对跑在其它 CPU 上的线程都是不可见 的。这种方式可能导致每个线程拥有这个共享对象的私有拷贝，每个拷贝停留在不同的 CPU 缓存中。
 
第 9 章 Java 内存模型 | 67
 下图示意了这种情形。跑在左边 CPU 的线程拷贝这个共享对象到它的 CPU 缓存中，然后将 count 变量的值修 改为 2。这个修改对跑在右边 CPU 上的其它线程是不可见的，因为修改后的 count 的值还没有被刷新回主存中 去。
解决这个问题你可以使用 Java 中的 volatile 关键字。volatile 关键字可以保证直接从主存中读取一个变量，如果 这个变量被修改后，总是会被写回到主存中去。
Race Conditions
如果两个或者更多的线程共享一个对象，多个线程在这个共享对象上更新变量，就有可能发生 race conditions。
想象一下，如果线程 A 读一个共享对象的变量 count 到它的 CPU 缓存中。再想象一下，线程 B 也做了同样的 事情，但是往一个不同的 CPU 缓存中。现在线程 A 将 count 加 1，线程 B 也做了同样的事情。现在 count 已 经被增在了两个，每个 CPU 缓存中一次。
如果这些增加操作被顺序的执行，变量 count 应该被增加两次，然后原值+2 被写回到主存中去。
然而，两次增加都是在没有适当的同步下并发执行的。无论是线程 A 还是线程 B 将 count 修改后的版本写回到 主存中取，修改后的值仅会被原值大 1，尽管增加了两次。
下图演示了上面描述的情况:
   
第 9 章 Java 内存模型 | 68
 解决这个问题可以使用 Java 同步块。一个同步块可以保证在同一时刻仅有一个线程可以进入代码的临界区。同 步块还可以保证代码块中所有被访问的变量将会从主存中读入，当线程退出同步代码块时，所有被更新的变量都 会被刷新回主存中去，不管这个变量是否被声明为 volatile。


Java 同步关键字(synchronized)
Java 中的同步块用 synchronized 标记。同步块在 Java 中是同步在某个对象上。所有同步在一个对象上的同步 块在同时只能被一个线程进入并执行操作。所有其他等待进入该同步块的线程将被阻塞，直到执行该同步块中的 线程退出。
有四种不同的同步块:
1. 实例方法
2. 静态方法
3. 实例方法中的同步块 4. 静态方法中的同步块
上述同步块都同步在不同对象上。实际需要那种同步块视具体情况而定。

不要在字符串常量或全局对象中调用 wait()

死锁是两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。死锁通常发生在多个线程同时但以不同
的顺序请求同一组锁的时候。


更加复杂的死锁场景发生在数据库事务中

当多个线程需要相同的一些锁，但是按照不同的顺序加锁，死锁就很容易发生。

另外一个可以避免死锁的方法是在尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超 过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退 并释放所有已经获得的锁，然后等待一段随机的时间再重试。


死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。
每当一个线程获得了锁，会在线程和锁相关的数据结构中(map、graph 等等)将其记下。除此之外，每当有线 程请求锁，也需要记录在这个数据结构中。


一个可行的做法是释放所有锁，回退，并且等待一段随机的时间后重试。这个和简单的加锁超时类似，不一样的
是只有死锁已经发生了才回退，而不会是因为加锁的请求超时了。虽然有回退和等待，但是如果有大量的线程竞
争同一批锁，它们还是会重复地死锁(编者注:原因同超时类似，不能从根本上减轻竞争)。
一个更好的方案是给这些线程设置优先级，让一个(或几个)线程回退，剩下的线程就像没发生死锁一样继续保
持着它们需要的锁。如果赋予这些线程的优先级是固定不变的，同一批线程总是会拥有更高的优先级。为避免这
个问题，可以在死锁发生的时候设置随机的优先级。

在 Java 中，下面三个常见的原因会导致线程饥饿:
1. 高优先级线程吞噬所有的低优先级线程的 CPU 时间。
2. 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 3. 线程在等待一个本身(在其上调用 wait())也处于永久等待完成的对象，因为其他线程总是被持续地获得唤醒。


在 Java 中实现公平性
虽 Java 不可能实现 100% 的公平性，我们依然可以通过同步结构在线程间实现公平性的提高。

为了提高等待线程的公平性，我们使用锁方式来替代同步块。

注意到上面对 Lock 的实现，如果存在多线程并发访问 lock()，这些线程将阻塞在对 lock()方法的访问上。另 外，如果锁已经锁上(校对注:这里指的是 isLocked 等于 true 时)，这些线程将阻塞在 while(isLocked)循环 的 wait()调用里面。


下面来讲述将上面 Lock 类转变为公平锁 FairLock。你会注意到新的实现和之前的 Lock 类中的同步和 wait()/n otify()稍有不同。
准确地说如何从之前的 Lock 类做到公平锁的设计是一个渐进设计的过程，每一步都是在解决上一步的问题而前 进的:Nested Monitor Lockout, Slipped Conditions 和 Missed Signals。这些本身的讨论虽已超出本文的范 围，但其中每一步的内容都将会专题进行讨论。重要的是，每一个调用 lock()的线程都会进入一个队列，当解锁 后，只有队列里的第一个线程被允许锁住 Farlock 实例，所有其它的线程都将处于等待状态，直到他们处于队列 头部。


嵌套管程锁死类似于死锁， 下面是一个嵌套管程锁死的场景:
线程 1 获得 A 对象的锁。
线程 1 获得对象 B 的锁(同时持有对象 A 的锁)。
线程 1 决定等待另一个线程的信号再继续。
线程 1 调用 B.wait()，从而释放了 B 对象上的锁，但仍然持有对象 A 的锁。
线程 2 需要同时持有对象 A 和对象 B 的锁，才能向线程 1 发信号。
线程 2 无法获得对象 A 上的锁，因为对象 A 上的锁当前正被线程 1 持有。 线程 2 一直被阻塞，等待线程 1 释放对象 A 上的锁。
线程 1 一直阻塞，等待线程 2 的信号，因此，不会释放对象 A 上的锁， 而线程 2 需要对象 A 上的锁才能给线程 1 发信号......

死锁中，二个线程都在等待对方释放锁。
嵌套管程锁死中，线程 1 持有锁 A，同时等待从线程 2 发来的信号，线程 2 需要锁 A 来发信号给线程 

所谓 Slipped conditions，就是说， 从一个线程检查某一特定条件到该线程操作此条件期间，这个条件已经被其 它线程改变，导致第一个线程在该条件上执行了错误的操作。这里有一个简单的例子:



读/写锁的 Java 实现


如果某个线程想要读取资源，只要没有线程正在对该资源进行写操作且没有线程请求对该资源的写操作即可。我 们假设对写操作的请求比对读操作的请求更重要，就要提升写请求的优先级。此外，如果读操作发生的比较频 繁，我们又没有提升写操作的优先级，那么就会产生“饥饿”现象。请求写操作的线程会一直阻塞，直到所有的 读线程都从 ReadWriteLock 上解锁了。如果一直保证新线程的读操作权限，那么等待写操作的线程就会一直阻 塞下去，结果就是发生“饥饿”。因此，只有当没有线程正在锁住 ReadWriteLock 进行写操作，且没有线程请 求该锁准备执行写操作时，才能保证读操作继续


Semaphore(信号量)是一个线程同步结构，用于在线程间传递信号，以避免出现信号丢失(译者注:下文会 具体介绍)，或者像锁一样用于保护一个关键区域。自从 5.0 开始，jdk 在 java.util.concurrent 包里提供了 Se maphore 的官方实现，因此大家不需要自己去实现 Semaphore。但是还是很有必要去熟悉如何使用 Semaph ore 及其背后的原理

Blocking Queue
阻塞队列与普通队列的区别在于，当队列是空的时，从队列中获取元素的操作将会被阻塞，或者当队列是满
时，往队列里添加元素的操作会被阻塞。试图从空的阻塞队列中获取元素的线程将会被阻塞，直到其他的线程往
空的队列插入新的元素。同样，试图往已满的阻塞队列中添加新元素的线程同样也会被阻塞，直到其他的线程使
队列重新变得空闲起来，如从队列中移除一个或者多个元素，或者完全清空队列

CAS(Compare and swap)比较和替换是设计并发算法时用到的一种技术。简单来说，比较和替换是使用一 个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量 的值。

阻塞算法和非阻塞算法的主要不同在于上面两部分描述的它们的行为的第二步。换句话说，它们之间的不同在于
当请求操作不能够执行时阻塞算法和非阻塞算法会怎么做。
阻塞算法会阻塞线程知道请求操作可以被执行。非阻塞算法会通知请求线程操作不能够被执行，并返回。


Java 中的 volatile 变量是直接从主存中读取值的变量。当一个新的值赋给一个 volatile 变量时，这个值总是会被 立即写回到主存中去。这样就确保了，一个 volatile 变量最新的值总是对跑在其他 CPU 上的线程可见。其他线 程每次会从主存中读取变量的值，而不是比如线程所运行 CPU 的 CPU 缓存中。


